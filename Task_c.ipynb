{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:50.093719Z",
     "iopub.status.busy": "2021-08-22T22:48:50.092887Z",
     "iopub.status.idle": "2021-08-22T22:48:55.071275Z",
     "shell.execute_reply": "2021-08-22T22:48:55.070475Z",
     "shell.execute_reply.started": "2021-08-22T22:48:50.093610Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Image Info from CSV and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:55.073084Z",
     "iopub.status.busy": "2021-08-22T22:48:55.072735Z",
     "iopub.status.idle": "2021-08-22T22:48:55.176652Z",
     "shell.execute_reply": "2021-08-22T22:48:55.175802Z",
     "shell.execute_reply.started": "2021-08-22T22:48:55.073046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name                                     text_corrected  \\\n",
       "0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
       "2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
       "4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "       humour          sarcasm       offensive      motivational  \\\n",
       "0   hilarious          general   not_offensive  not_motivational   \n",
       "1   not_funny          general   not_offensive      motivational   \n",
       "2  very_funny    not_sarcastic   not_offensive  not_motivational   \n",
       "3  very_funny  twisted_meaning  very_offensive      motivational   \n",
       "4   hilarious     very_twisted  very_offensive  not_motivational   \n",
       "\n",
       "  overall_sentiment  \n",
       "0     very_positive  \n",
       "1     very_positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4           neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/memotion-dataset-7k/memotion_dataset_7k/labels.csv')\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df = df.drop(columns = ['text_ocr'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:55.180129Z",
     "iopub.status.busy": "2021-08-22T22:48:55.179885Z",
     "iopub.status.idle": "2021-08-22T22:48:55.201846Z",
     "shell.execute_reply": "2021-08-22T22:48:55.200882Z",
     "shell.execute_reply.started": "2021-08-22T22:48:55.180104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>image_120.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>image_4800.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>image_6782.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>image_6785.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>image_6787.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_name text_corrected      humour          sarcasm  \\\n",
       "119    image_120.jpg            NaN   not_funny          general   \n",
       "4799  image_4800.jpg            NaN  very_funny          general   \n",
       "6781  image_6782.jpg            NaN  very_funny  twisted_meaning   \n",
       "6784  image_6785.jpg            NaN   hilarious          general   \n",
       "6786  image_6787.jpg            NaN   not_funny    not_sarcastic   \n",
       "\n",
       "           offensive      motivational overall_sentiment  \n",
       "119    not_offensive  not_motivational          positive  \n",
       "4799          slight      motivational           neutral  \n",
       "6781   not_offensive  not_motivational          positive  \n",
       "6784   not_offensive  not_motivational          positive  \n",
       "6786  very_offensive      motivational          positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:55.204113Z",
     "iopub.status.busy": "2021-08-22T22:48:55.203720Z",
     "iopub.status.idle": "2021-08-22T22:48:55.234999Z",
     "shell.execute_reply": "2021-08-22T22:48:55.234259Z",
     "shell.execute_reply.started": "2021-08-22T22:48:55.204076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name           False\n",
       "text_corrected       False\n",
       "humour               False\n",
       "sarcasm              False\n",
       "offensive            False\n",
       "motivational         False\n",
       "overall_sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = df.copy()\n",
    "cleaned.dropna(inplace=True)\n",
    "cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:55.237950Z",
     "iopub.status.busy": "2021-08-22T22:48:55.237704Z",
     "iopub.status.idle": "2021-08-22T22:48:55.246223Z",
     "shell.execute_reply": "2021-08-22T22:48:55.245469Z",
     "shell.execute_reply.started": "2021-08-22T22:48:55.237926Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image(dataframe):\n",
    "    \n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "    width = 100\n",
    "    height = 100\n",
    "    X = []\n",
    "    path = '../input/memotion-dataset-7k/memotion_dataset_7k/images/'+dataframe['image_name']\n",
    "    \n",
    "    for i in tqdm(range(dataframe.shape[0])):\n",
    "        if i in [119, 4799, 6781, 6784, 6786]:\n",
    "            pass\n",
    "        else:\n",
    "            img = image.load_img(path[i],target_size=(width,height,3))\n",
    "            img = ImageOps.grayscale(img)\n",
    "            img = image.img_to_array(img)\n",
    "            img = img/255.0\n",
    "            X.append(img)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], 100*100)\n",
    "    \n",
    "    rows_to_drop = ['image_120.jpg', 'image_4800.jpg', 'image_6782.jpg', 'image_6785.jpg', 'image_6787.jpg',\n",
    "                    'image_6988.jpg', 'image_6989.jpg', 'image_6990.png', 'image_6991.jpg', 'image_6992.jpg']\n",
    "    \n",
    "    for images in rows_to_drop:\n",
    "        dataframe.drop(dataframe[dataframe['image_name'] == images].index, inplace=True)\n",
    "        \n",
    "    text_data = CountVectorizer().fit_transform(dataframe['text_corrected'].values)\n",
    "    text_data = TfidfTransformer().fit_transform(text_data).toarray()\n",
    "    \n",
    "    features = np.hstack((X, text_data))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:48:55.248234Z",
     "iopub.status.busy": "2021-08-22T22:48:55.247704Z",
     "iopub.status.idle": "2021-08-22T22:50:09.218075Z",
     "shell.execute_reply": "2021-08-22T22:50:09.217119Z",
     "shell.execute_reply.started": "2021-08-22T22:48:55.248195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 6672/6987 [01:09<00:02, 109.88it/s]/opt/conda/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|██████████| 6987/6987 [01:12<00:00, 96.10it/s] \n"
     ]
    }
   ],
   "source": [
    "X = get_image(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:50:09.219777Z",
     "iopub.status.busy": "2021-08-22T22:50:09.219417Z",
     "iopub.status.idle": "2021-08-22T22:50:09.226283Z",
     "shell.execute_reply": "2021-08-22T22:50:09.225326Z",
     "shell.execute_reply.started": "2021-08-22T22:50:09.219742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6982, 22915)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:50:09.230098Z",
     "iopub.status.busy": "2021-08-22T22:50:09.229543Z",
     "iopub.status.idle": "2021-08-22T22:50:09.239271Z",
     "shell.execute_reply": "2021-08-22T22:50:09.238502Z",
     "shell.execute_reply.started": "2021-08-22T22:50:09.230058Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_target(dataframe):\n",
    "    target_A = dataframe.copy()['overall_sentiment']\n",
    "    target_A = pd.get_dummies(target_A)\n",
    "    \n",
    "    target_B = dataframe.copy()\n",
    "    target_B = target_B.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious':1},\n",
    "                        'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1},\n",
    "                        'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1},\n",
    "                        'motivational': {'not_motivational': 0, 'motivational': 1}})\n",
    "    target_B = target_B.iloc[:,2:6]\n",
    "    \n",
    "    df1 = pd.get_dummies(cleaned['sarcasm'])\n",
    "    df2 = pd.get_dummies(cleaned['humour'])\n",
    "    df3 = pd.get_dummies(cleaned['offensive'])\n",
    "    df4 = pd.get_dummies(cleaned['offensive'])\n",
    "    frames = [df1, df2, df3, df4]\n",
    "    target_C = pd.concat(frames, axis=1)\n",
    "    \n",
    "    return target_A, target_B, target_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:50:09.241826Z",
     "iopub.status.busy": "2021-08-22T22:50:09.241145Z",
     "iopub.status.idle": "2021-08-22T22:50:09.287451Z",
     "shell.execute_reply": "2021-08-22T22:50:09.286670Z",
     "shell.execute_reply.started": "2021-08-22T22:50:09.241757Z"
    }
   },
   "outputs": [],
   "source": [
    "target_A, target_B, target_C = create_target(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:50:09.289042Z",
     "iopub.status.busy": "2021-08-22T22:50:09.288672Z",
     "iopub.status.idle": "2021-08-22T22:50:09.293260Z",
     "shell.execute_reply": "2021-08-22T22:50:09.292240Z",
     "shell.execute_reply.started": "2021-08-22T22:50:09.289000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T22:50:09.295600Z",
     "iopub.status.busy": "2021-08-22T22:50:09.294985Z",
     "iopub.status.idle": "2021-08-22T23:04:00.022224Z",
     "shell.execute_reply": "2021-08-22T23:04:00.021382Z",
     "shell.execute_reply.started": "2021-08-22T22:50:09.295561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3419767004885381\n",
      "0.18885383078931467\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\n",
    "\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T23:04:00.028584Z",
     "iopub.status.busy": "2021-08-22T23:04:00.026408Z",
     "iopub.status.idle": "2021-08-22T23:18:26.247734Z",
     "shell.execute_reply": "2021-08-22T23:18:26.246858Z",
     "shell.execute_reply.started": "2021-08-22T23:04:00.028539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827956989247314\n",
      "0.6295084609351305\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T23:18:26.249627Z",
     "iopub.status.busy": "2021-08-22T23:18:26.249118Z",
     "iopub.status.idle": "2021-08-23T00:07:49.496317Z",
     "shell.execute_reply": "2021-08-23T00:07:49.495466Z",
     "shell.execute_reply.started": "2021-08-22T23:18:26.249587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32540348913144884\n",
      "0.23449363007427143\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:07:49.498310Z",
     "iopub.status.busy": "2021-08-23T00:07:49.497743Z",
     "iopub.status.idle": "2021-08-23T00:10:55.031587Z",
     "shell.execute_reply": "2021-08-23T00:10:55.030037Z",
     "shell.execute_reply.started": "2021-08-23T00:07:49.498273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1690793283149971\n",
      "0.0693352614551758\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:10:55.033115Z",
     "iopub.status.busy": "2021-08-23T00:10:55.032772Z",
     "iopub.status.idle": "2021-08-23T00:12:54.744696Z",
     "shell.execute_reply": "2021-08-23T00:12:54.743032Z",
     "shell.execute_reply.started": "2021-08-23T00:10:55.033078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7735724647237241\n",
      "0.6349300994907526\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:12:54.746334Z",
     "iopub.status.busy": "2021-08-23T00:12:54.745992Z",
     "iopub.status.idle": "2021-08-23T00:22:07.784692Z",
     "shell.execute_reply": "2021-08-23T00:22:07.783930Z",
     "shell.execute_reply.started": "2021-08-23T00:12:54.746297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14075187969924813\n",
      "0.06273088011361082\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:22:07.786224Z",
     "iopub.status.busy": "2021-08-23T00:22:07.785889Z",
     "iopub.status.idle": "2021-08-23T00:41:10.055063Z",
     "shell.execute_reply": "2021-08-23T00:41:10.054165Z",
     "shell.execute_reply.started": "2021-08-23T00:22:07.786187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3322569070685325\n",
      "0.20837322388569451\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:41:10.056822Z",
     "iopub.status.busy": "2021-08-23T00:41:10.056307Z",
     "iopub.status.idle": "2021-08-23T00:45:52.702991Z",
     "shell.execute_reply": "2021-08-23T00:45:52.702174Z",
     "shell.execute_reply.started": "2021-08-23T00:41:10.056784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6662842392083752\n",
      "0.6192618744099043\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:45:52.704530Z",
     "iopub.status.busy": "2021-08-23T00:45:52.704186Z",
     "iopub.status.idle": "2021-08-23T01:43:38.720114Z",
     "shell.execute_reply": "2021-08-23T01:43:38.718458Z",
     "shell.execute_reply.started": "2021-08-23T00:45:52.704494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32310292678587316\n",
      "0.2435076651425948\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
